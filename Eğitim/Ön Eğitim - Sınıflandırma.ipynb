{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ön Eğitim - Sınıflandırma\n",
    "Bu çalışmada ilk ön eğitim tekniğimizi inceliyoruz. Topladığımız Mandalina emoji veri setiyle transformers modellerini eğitiyoruz. Bu eğitimde iki tane hedefimiz var.\n",
    "\n",
    "Birincisi BERT'te de kullanılan Maskelenmiş Dil Modeli (Masked Language Model)\n",
    "İkincisi ise *Mandalina emoji veri setindeki* twitlerden emojileri çıkartıp her twitte geçen emojinin kategorisini 8 sınıf arasından tahmin ediyoruz.\n",
    "Kategoriler\n",
    "* laughing = kahkaha\n",
    "\n",
    "😀 😃 😄 😁 😆 😅 🤣 😂\n",
    "* smiling = gülücük\n",
    "\n",
    "🙂 🙃 😉 😊 😇\n",
    "* affection = ilgi\n",
    "\n",
    "🥰 😍 🤩 😘 😗 😚 😙\n",
    "* tongue = dil\n",
    "\n",
    "😛 😜 🤪 😝 🤑\n",
    "* neutral = nötr\n",
    "\n",
    "🤐 🤨 😐 😑 😶\n",
    "* unwell = hasta\n",
    "\n",
    "😷 🤒 🤕 🤢 🤮 🤧 🥵 🥶 🥴 😵\n",
    "* concerned = endişeli\n",
    "\n",
    "😕 😟 🙁 ☹️ 😮 😯 😲 😳 🥺 😦 😧 😨 😰 😥 😢 😭 😖 😣 😞 😓 😩 😫\n",
    "* negative = negatif\n",
    "\n",
    "😤 😡 😠 🤬 😈 👿\n",
    "\n",
    "***\n",
    "\n",
    "Not: Bu modelin eğitimi uzun sürüyor, bu sebeple iyi bir GPU kullanılması önerilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerekli kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from transformers import AdamW, AutoConfig, AutoModelForPreTraining, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from random import random as rand\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import os\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00003\n",
    "wd = 0.1\n",
    "loss_multiplier = 5\n",
    "transformer_name = \"distilberturk\"\n",
    "\n",
    "# Transformerdaki CLS ve SEP taglerinin tanımlanması\n",
    "cls_tag = 101\n",
    "sep_tag = 102\n",
    "if transformer_name==\"distilberturk\":\n",
    "    cls_tag = 2\n",
    "    sep_tag = 3\n",
    "\n",
    "embedding_layer = True\n",
    "last_free_layer = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mandalina Emoji Verisi\n",
    "df = pd.read_csv(\"../Veriler/emoji.csv\", index_col=0)\n",
    "all_labels = sorted(list(set(df[\"emoji class\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transformer_name==\"mbert\":\n",
    "    config = AutoConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "    config.output_hidden_states = True\n",
    "elif transformer_name==\"distilberturk\":\n",
    "    config = AutoConfig.from_pretrained('dbmdz/distilbert-base-turkish-cased')\n",
    "    config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maskelenmiş Dil Modeli'nin eklendiği modelin tanımlanması "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls', 'pooler', 'vocab', 'embedding', 'transformer.layer.0', 'transformer.layer.1', 'transformer.layer.2', 'transformer.layer.3', 'transformer.layer.4', 'transformer.layer.5', 'transformer.layer.6', 'transformer.layer.7', 'transformer.layer.8', 'transformer.layer.9', 'transformer.layer.10', 'transformer.layer.11']\n",
      "[FREE]: distilbert.embeddings.word_embeddings.weight\n",
      "[FREE]: distilbert.embeddings.position_embeddings.weight\n",
      "[FREE]: distilbert.embeddings.LayerNorm.weight\n",
      "[FREE]: distilbert.embeddings.LayerNorm.bias\n",
      "[FREE]: distilbert.transformer.layer.0.attention.q_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.0.attention.q_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.0.attention.k_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.0.attention.k_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.0.attention.v_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.0.attention.v_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.0.attention.out_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.0.attention.out_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.0.sa_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.0.sa_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.0.ffn.lin1.weight\n",
      "[FREE]: distilbert.transformer.layer.0.ffn.lin1.bias\n",
      "[FREE]: distilbert.transformer.layer.0.ffn.lin2.weight\n",
      "[FREE]: distilbert.transformer.layer.0.ffn.lin2.bias\n",
      "[FREE]: distilbert.transformer.layer.0.output_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.0.output_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.1.attention.q_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.1.attention.q_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.1.attention.k_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.1.attention.k_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.1.attention.v_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.1.attention.v_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.1.attention.out_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.1.attention.out_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.1.sa_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.1.sa_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.1.ffn.lin1.weight\n",
      "[FREE]: distilbert.transformer.layer.1.ffn.lin1.bias\n",
      "[FREE]: distilbert.transformer.layer.1.ffn.lin2.weight\n",
      "[FREE]: distilbert.transformer.layer.1.ffn.lin2.bias\n",
      "[FREE]: distilbert.transformer.layer.1.output_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.1.output_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.2.attention.q_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.2.attention.q_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.2.attention.k_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.2.attention.k_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.2.attention.v_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.2.attention.v_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.2.attention.out_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.2.attention.out_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.2.sa_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.2.sa_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.2.ffn.lin1.weight\n",
      "[FREE]: distilbert.transformer.layer.2.ffn.lin1.bias\n",
      "[FREE]: distilbert.transformer.layer.2.ffn.lin2.weight\n",
      "[FREE]: distilbert.transformer.layer.2.ffn.lin2.bias\n",
      "[FREE]: distilbert.transformer.layer.2.output_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.2.output_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.3.attention.q_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.3.attention.q_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.3.attention.k_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.3.attention.k_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.3.attention.v_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.3.attention.v_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.3.attention.out_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.3.attention.out_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.3.sa_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.3.sa_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.3.ffn.lin1.weight\n",
      "[FREE]: distilbert.transformer.layer.3.ffn.lin1.bias\n",
      "[FREE]: distilbert.transformer.layer.3.ffn.lin2.weight\n",
      "[FREE]: distilbert.transformer.layer.3.ffn.lin2.bias\n",
      "[FREE]: distilbert.transformer.layer.3.output_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.3.output_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.4.attention.q_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.4.attention.q_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.4.attention.k_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.4.attention.k_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.4.attention.v_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.4.attention.v_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.4.attention.out_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.4.attention.out_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.4.sa_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.4.sa_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.4.ffn.lin1.weight\n",
      "[FREE]: distilbert.transformer.layer.4.ffn.lin1.bias\n",
      "[FREE]: distilbert.transformer.layer.4.ffn.lin2.weight\n",
      "[FREE]: distilbert.transformer.layer.4.ffn.lin2.bias\n",
      "[FREE]: distilbert.transformer.layer.4.output_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.4.output_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.5.attention.q_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.5.attention.q_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.5.attention.k_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.5.attention.k_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.5.attention.v_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.5.attention.v_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.5.attention.out_lin.weight\n",
      "[FREE]: distilbert.transformer.layer.5.attention.out_lin.bias\n",
      "[FREE]: distilbert.transformer.layer.5.sa_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.5.sa_layer_norm.bias\n",
      "[FREE]: distilbert.transformer.layer.5.ffn.lin1.weight\n",
      "[FREE]: distilbert.transformer.layer.5.ffn.lin1.bias\n",
      "[FREE]: distilbert.transformer.layer.5.ffn.lin2.weight\n",
      "[FREE]: distilbert.transformer.layer.5.ffn.lin2.bias\n",
      "[FREE]: distilbert.transformer.layer.5.output_layer_norm.weight\n",
      "[FREE]: distilbert.transformer.layer.5.output_layer_norm.bias\n",
      "[FREE]: vocab_transform.weight\n",
      "[FREE]: vocab_transform.bias\n",
      "[FREE]: vocab_layer_norm.weight\n",
      "[FREE]: vocab_layer_norm.bias\n",
      "[FREE]: vocab_projector.bias\n",
      "Combined Net tanımlandı.\n"
     ]
    }
   ],
   "source": [
    "class Combined_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Combined_Net, self).__init__()\n",
    "        if transformer_name==\"distilberturk\":\n",
    "            self.net_bert = AutoModelForPreTraining.from_config(config).from_pretrained('dbmdz/distilbert-base-turkish-cased', output_hidden_states=True)\n",
    "        elif transformer_name==\"mbert\":\n",
    "            self.net_bert = AutoModelForPreTraining.from_config(config).from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)\n",
    "        unfrozen_layers = [\"cls\", \"pooler\", \"vocab\"]\n",
    "        if embedding_layer:\n",
    "            unfrozen_layers.append('embedding')\n",
    "        \n",
    "        for idx in range(last_free_layer, 12):\n",
    "            if transformer_name==\"distilberturk\":\n",
    "                unfrozen_layers.append('transformer.layer.'+str(idx))\n",
    "            elif transformer_name==\"mbert\":\n",
    "                unfrozen_layers.append('encoder.layer.'+str(idx))\n",
    "            \n",
    "        print(unfrozen_layers)\n",
    "        for name, param in self.net_bert.named_parameters():\n",
    "            if not any([layer in name for layer in unfrozen_layers]):\n",
    "                print(\"[FROZE]: %s\" % name)\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                print(\"[FREE]: %s\" % name)\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 8)\n",
    "\n",
    "    def forward(self, input_ids, input_attention, input_types, input_ids_masked, input_attention_masked, input_types_masked):\n",
    "        if transformer_name==\"mbert\":\n",
    "            _, _, x  = self.net_bert(input_ids, attention_mask=input_attention, token_type_ids=input_types)\n",
    "            probs, _, _  = self.net_bert(input_ids_masked, attention_mask=input_attention_masked, token_type_ids=input_types_masked)\n",
    "        elif transformer_name==\"distilberturk\":\n",
    "            _, x  = self.net_bert(input_ids, attention_mask=input_attention)\n",
    "            probs, _  = self.net_bert(input_ids_masked, attention_mask=input_attention_masked)\n",
    "    \n",
    "        #Getting head\n",
    "        x = x[-1][:,0,:]\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        return x, probs\n",
    "    \n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "try:\n",
    "    combined_net.apply(weight_reset)\n",
    "    print('Combined Net resetlendi.')\n",
    "except: \n",
    "    pass\n",
    "\n",
    "combined_net = Combined_Net().to(device)\n",
    "print('Combined Net tanımlandı.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transformer_name==\"distilberturk\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained('dbmdz/distilbert-base-turkish-cased')\n",
    "elif transformer_name==\"mbert\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maskelenmiş Dil Modeli için otomatik bir şekilde eğitim verisinin oluşturulması ve öznitelik çıkarma kodları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_vocabs = list(tokenizer.vocab.keys())\n",
    "def to_masked(original_sent):\n",
    "\n",
    "    max_pred = 20\n",
    "    mask_prob = 0.15\n",
    "    max_len = 256\n",
    "    first_part = list(tokenizer.encode(original_sent, add_special_tokens=False))\n",
    "    feature = [cls_tag]+first_part+[sep_tag]\n",
    "    if len(feature)>256:\n",
    "        print('Error in ',original_sent)\n",
    "        feature = feature[:255]+[sep_tag]\n",
    "    mid_index = len(first_part)+2\n",
    "    input_type = [0]*mid_index+(len(feature)-mid_index)*[1]\n",
    "    \n",
    "    masked_tokens = []\n",
    "    masked_pos = []\n",
    "    tokens = tokenizer.convert_ids_to_tokens(feature)\n",
    "    input_mask = [1]*len(tokens)\n",
    "    n_pred = min(max_pred, max(1, int(round(len(tokens)*mask_prob))))\n",
    "    cand_pos = [i for i, token in enumerate(tokens)\n",
    "                if token != '[CLS]' and token != '[SEP]' and token != '[unused5]']\n",
    "    shuffle(cand_pos)\n",
    "\n",
    "    for pos in cand_pos[:n_pred]:\n",
    "        masked_tokens.append(tokens[pos])\n",
    "        masked_pos.append(pos)\n",
    "        if rand() < 0.8: # 80%\n",
    "            tokens[pos] = '[MASK]'\n",
    "        elif rand() < 0.5: # 10%\n",
    "            tokens[pos] = tokenizer_vocabs[random.randrange(len(tokenizer_vocabs))]\n",
    "\n",
    "            \n",
    "#     masked_weights = [1]*len(masked_tokens)\n",
    "    \n",
    "    masked_lm_labels = [-100]*max_len\n",
    "    for pos in masked_pos:\n",
    "        masked_lm_labels[pos] = feature[pos]\n",
    "    # Token Indexing\n",
    "    input_ids = tokenizer.encode(tokens, add_special_tokens=False)\n",
    "#     masked_ids = tokenizer.encode(masked_tokens, add_special_tokens=False)\n",
    "    n_pad = max_len - len(input_ids)\n",
    "    input_ids.extend([0]*n_pad)\n",
    "    input_mask.extend([0]*n_pad)\n",
    "    input_type.extend([0]*n_pad)\n",
    "    \n",
    "        # Zero Padding for masked target\n",
    "#     if max_pred > n_pred:\n",
    "#         n_pad = max_pred - n_pred\n",
    "#         masked_ids.extend([0]*n_pad)\n",
    "#         masked_pos.extend([0]*n_pad)\n",
    "#         masked_weights.extend([0]*n_pad)\n",
    "\n",
    "    return torch.tensor(input_ids), torch.tensor(input_mask), torch.tensor(input_type), torch.tensor(masked_lm_labels)\n",
    "\n",
    "def to_masked_all(X):\n",
    "    ids = []\n",
    "    mask = []\n",
    "    types = []\n",
    "    labels = []\n",
    "    for _, original_sent in X:\n",
    "        try:\n",
    "            input_ids, input_mask, input_type, masked_lm_labels = to_masked(original_sent)\n",
    "        except:\n",
    "            print(original_sent)\n",
    "            raise Exception\n",
    "        ids.append(input_ids)\n",
    "        mask.append(input_mask)\n",
    "        types.append(input_type)\n",
    "        labels.append(masked_lm_labels)\n",
    "    return torch.stack(ids),torch.stack(mask),torch.stack(types),torch.stack(labels)\n",
    "\n",
    "def to_id(text):\n",
    "    ids_1 = tokenizer.encode(text, add_special_tokens=False)\n",
    "    return torch.tensor([cls_tag]+ids_1+[sep_tag])\n",
    "\n",
    "def feat_ext(data):\n",
    "    features = []\n",
    "    attention_masks = []\n",
    "    type_ids = []\n",
    "    max_len = 256\n",
    "    for input_ids, _ in data:\n",
    "        first_ind = list(input_ids).index(sep_tag)+1\n",
    "        if transformer_name==\"distilberturk\":\n",
    "            type_id = []\n",
    "        elif transformer_name==\"mbert\":\n",
    "            type_id = torch.cat((torch.LongTensor([0]*(first_ind)), torch.LongTensor([1]*(len(input_ids)-first_ind)),torch.LongTensor([0]*(max_len-len(input_ids)))), 0)\n",
    "        attention_mask = torch.cat((torch.tensor([1.0]*(len(input_ids))), torch.tensor([0.0]*(max_len-len(input_ids)))), 0)\n",
    "        input_ids = torch.cat((input_ids, torch.tensor([0]*(max_len-len(input_ids)))), 0)        \n",
    "        attention_masks.append(attention_mask)\n",
    "        features.append(input_ids)\n",
    "        type_ids.append(torch.tensor(type_id))\n",
    "    return torch.stack(features),torch.stack(attention_masks),torch.stack(type_ids)\n",
    "\n",
    "def feat_ext_batch(subset_df):\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        id_seq = to_id(row['text'])\n",
    "        if len(id_seq)>=256:\n",
    "            ct+=1\n",
    "            continue\n",
    "        X.append((id_seq, row['text']))\n",
    "        y.append(all_labels.index(row['emoji class']))\n",
    "    X_feat, X_attention, X_types = feat_ext(X)\n",
    "    X_feat_masked, X_attention_masked, X_types_masked, X_masked_lm_labels = to_masked_all(X)\n",
    "    y = torch.tensor(y)\n",
    "    return X_feat, X_attention, X_types, X_feat_masked, X_attention_masked, X_types_masked, X_masked_lm_labels, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoji veri setinin eğitim ve test kısımlarının ayrılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.95\n",
    "train_df = df[msk]\n",
    "test_df = df[~msk].reset_index(drop=True)\n",
    "msk = np.random.rand(len(train_df)) < 0.94\n",
    "val_df = train_df[~msk].reset_index(drop=True)\n",
    "train_df = train_df[msk].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer ve loss fonksiyonun belirlenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "lm_criterion = CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(combined_net.parameters(), lr=learning_rate,  correct_bias=False, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dil modeli ve emoji sınıflandırma için tahminleri dönen kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df):\n",
    "    batch_size = 4\n",
    "    lm_loss = 0\n",
    "    cl_loss = 0\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.tensor([], device='cpu')\n",
    "        y_test = torch.LongTensor([], device='cpu')\n",
    "        for idx in tqdm(range(math.ceil(len(df)/batch_size)), total=math.ceil(len(df)/batch_size)):\n",
    "            inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m, input_masked_labels, y_test_sub = feat_ext_batch(df[idx*batch_size: min(len(df), (idx+1)*batch_size)])\n",
    "\n",
    "            inputs_0 = inputs_0.to(device)\n",
    "            input_attention = input_attention.to(device)\n",
    "            input_type = input_type.to(device)\n",
    "            inputs_0_m = inputs_0_m.to(device)\n",
    "            input_attention_m = input_attention_m.to(device)\n",
    "            input_type_m = input_type_m.to(device)\n",
    "\n",
    "            o, probs = combined_net(inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m) \n",
    "            outputs = torch.cat((outputs, o.to('cpu')), 0)\n",
    "            y_test = torch.cat((y_test, y_test_sub), 0)\n",
    "            \n",
    "            lm_loss += lm_criterion(probs.to('cpu').view(-1, config.vocab_size), input_masked_labels.view(-1))\n",
    "            cl_loss += criterion(o.to('cpu'), y_test_sub)\n",
    "        _, predicted_test = torch.max(outputs.data, 1)\n",
    "        total = y_test.size(0)\n",
    "        correct = (predicted_test == y_test).sum().item()\n",
    "        test_acc = correct/total\n",
    "\n",
    "    test_f1 = f1_score(predicted_test.cpu(), y_test.cpu(), average=\"weighted\")\n",
    "    return test_f1, test_acc, lm_loss, cl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1_1-0,    64/171287] loss: 15.373 lm_loss: 4.758 cl_loss: 2.123  |  accuracy: 0.059\n",
      "[1_2-0,   128/171287] loss: 14.778 lm_loss: 4.516 cl_loss: 2.052  |  accuracy: 0.137\n",
      "[1_3-0,   192/171287] loss: 14.461 lm_loss: 4.435 cl_loss: 2.005  |  accuracy: 0.159\n",
      "[1_4-0,   256/171287] loss: 14.703 lm_loss: 4.303 cl_loss: 2.080  |  accuracy: 0.163\n",
      "[1_5-0,   320/171287] loss: 14.433 lm_loss: 4.212 cl_loss: 2.044  |  accuracy: 0.170\n",
      "[1_6-0,   384/171287] loss: 14.310 lm_loss: 4.261 cl_loss: 2.010  |  accuracy: 0.178\n",
      "[1_7-0,   448/171287] loss: 14.169 lm_loss: 4.184 cl_loss: 1.997  |  accuracy: 0.181\n",
      "[1_8-0,   512/171287] loss: 14.317 lm_loss: 4.275 cl_loss: 2.008  |  accuracy: 0.177\n",
      "[1_9-0,   576/171287] loss: 14.066 lm_loss: 4.154 cl_loss: 1.982  |  accuracy: 0.188\n",
      "[1_10-0,   640/171287] loss: 14.440 lm_loss: 4.392 cl_loss: 2.010  |  accuracy: 0.191\n",
      "[1_11-0,   704/171287] loss: 14.045 lm_loss: 4.265 cl_loss: 1.956  |  accuracy: 0.199\n",
      "[1_12-0,   768/171287] loss: 14.169 lm_loss: 4.214 cl_loss: 1.991  |  accuracy: 0.203\n",
      "[1_13-0,   832/171287] loss: 14.252 lm_loss: 4.234 cl_loss: 2.003  |  accuracy: 0.201\n",
      "[1_14-0,   896/171287] loss: 14.257 lm_loss: 4.281 cl_loss: 1.995  |  accuracy: 0.203\n",
      "[1_15-0,   960/171287] loss: 14.333 lm_loss: 4.425 cl_loss: 1.982  |  accuracy: 0.205\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f66c21f02c3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_multiplier\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcl_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlm_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m             \u001b[0;31m# Wait for several backward steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "batch_size = 4\n",
    "best_val_loss = np.inf\n",
    "accumulation_steps = 64\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_cl_loss = 0.0\n",
    "    running_lm_loss = 0.0\n",
    "    total_loss = 0\n",
    "    total_cl_loss = 0.0\n",
    "    total_lm_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "    val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "    train_outputs = torch.LongTensor([]).to(device)\n",
    "    for idx in range(math.ceil(len(train_df)/batch_size)):\n",
    "        inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m, input_masked_labels, labels = feat_ext_batch(train_df[idx*batch_size: min(len(train_df), (idx+1)*batch_size)])\n",
    "        inputs_0 = inputs_0.to(device)\n",
    "        input_attention = input_attention.to(device)\n",
    "        input_type = input_type.to(device)\n",
    "        inputs_0_m = inputs_0_m.to(device)\n",
    "        input_attention_m = input_attention_m.to(device)\n",
    "        input_type_m = input_type_m.to(device)\n",
    "        input_masked_labels = input_masked_labels.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs, probs = combined_net(inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m)\n",
    "        \n",
    "        lm_loss = lm_criterion(probs.view(-1, config.vocab_size), input_masked_labels.view(-1)) / accumulation_steps \n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total+= len(labels)\n",
    "        train_outputs = torch.cat((train_outputs, predicted), 0)\n",
    "        # forward + backward + optimize\n",
    "        cl_loss = criterion(outputs, labels) / accumulation_steps \n",
    "        \n",
    "        loss = loss_multiplier*cl_loss + lm_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        if (idx+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()                           # Reset gradients tensors\n",
    "#             scheduler.step()\n",
    "        \n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_cl_loss += cl_loss.item()\n",
    "        running_lm_loss += lm_loss.item()\n",
    "        if (idx+1) % accumulation_steps == 0:    # print every 2000 mini-batches\n",
    "            print('[%d_%d-%d, %5d/%d] loss: %.3f lm_loss: %.3f cl_loss: %.3f  |  accuracy: %.3f' %\n",
    "                  (epoch + 1, (idx + 1)//accumulation_steps,(idx + 1)%accumulation_steps, idx + 1, len(train_df)//batch_size, running_loss, running_lm_loss, running_cl_loss, correct/total))\n",
    "            total_loss += running_loss\n",
    "            total_cl_loss += running_cl_loss\n",
    "            total_lm_loss += running_lm_loss\n",
    "            running_loss = 0.0\n",
    "            running_cl_loss = 0 \n",
    "            running_lm_loss = 0\n",
    "        \n",
    "\n",
    "            \n",
    "    train_acc = correct/total\n",
    "    print(train_acc)\n",
    "    \n",
    "    test_f1, test_acc, test_lm_loss, test_cl_loss = get_predictions(test_df)\n",
    "    test_loss = (loss_multiplier*test_cl_loss) + test_lm_loss\n",
    "    val_f1, val_acc, val_lm_loss, val_cl_loss = get_predictions(val_df)\n",
    "    val_loss = (loss_multiplier*val_cl_loss) + val_lm_loss\n",
    "   \n",
    "    if True: #val_loss<best_val_loss:\n",
    "        now = datetime.now()\n",
    "        torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': combined_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': total_loss\n",
    "                }, f'../Models/{transformer_name}_emoji_f1_{test_f1}_acc_{test_acc}_{epoch+1}_big.pt')\n",
    "        if val_loss<best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "    print('Epoch: ',epoch+1)\n",
    "    print(f'Loss: {total_loss}, LM Loss: {total_lm_loss}, CL Loss: {total_cl_loss}, Training accuracy:{train_acc}, Validation accuracy:{val_acc}, Test accuracy:{test_acc}')\n",
    "    print(f'Val F1:{val_f1} \\t Val Loss: {val_loss} Val CL Loss: {val_cl_loss} Val LM Loss: {val_lm_loss}')\n",
    "    print(f'Test F1:{test_f1} \\t Test Loss: {test_loss} Test CL Loss: {test_cl_loss}  LM Loss: {val_lm_loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
