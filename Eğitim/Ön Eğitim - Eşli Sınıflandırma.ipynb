{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ã–n EÄŸitim - EÅŸli SÄ±nÄ±flandÄ±rma\n",
    "\n",
    "Bu Ã§alÄ±ÅŸmada ilk Ã¶n eÄŸitim notebook'unda olduÄŸu gibi maskeli dil modeli eÄŸitilmekte ve ek olarak emoji sÄ±nÄ±flandÄ±rmayÄ± ise eÅŸli bir ÅŸekilde yapÄ±yoruz.\n",
    "\n",
    "Bu yaklaÅŸÄ±m yine BERT'te olan bir sonraki cÃ¼mleyi sÄ±nÄ±flandÄ±rmaya (next sentence prediction) benziyor. Burada ikili bir ÅŸekilde eÅŸleÅŸtirdiÄŸimiz emojileri siliniÅŸ twitlerden, bu iki twitin aynÄ± emojiyi iÃ§erip iÃ§ermediÄŸini tahmin eden bir eÅŸli sÄ±nÄ±flandÄ±rma gÃ¶revi oluÅŸturmaktayÄ±z.\n",
    "\n",
    "Ã–rneÄŸin,\n",
    "Twit 1: Bu tam bir hayal kÄ±rÄ±klÄ±ÄŸÄ± ğŸ˜¦\n",
    "Twit 2: Ã‡ok mutluyum ğŸ™ƒ\n",
    "Twit 3: SÄ±nav iÃ§in Ã§ok stresliyim ğŸ˜¦\n",
    "\n",
    "iÃ§in\n",
    "\n",
    "*(\"Bu tam bir hayal kÄ±rÄ±klÄ±ÄŸÄ±\", \"Ã‡ok mutluyum\")* ikilisi farklÄ± kategorilerden emojiler iÃ§erdiÄŸi iÃ§in bunlarÄ±n farklÄ± olduÄŸunu modelimizin bu ÅŸekilde (0) ayÄ±rt etmesini istiyoruz.\n",
    "\n",
    "*(\"Bu tam bir hayal kÄ±rÄ±klÄ±ÄŸÄ±\", \"SÄ±nav iÃ§in Ã§ok stresliyim\")* ikilisi aynÄ± kategoriden emojiler iÃ§erdiÄŸi iÃ§in bunlarÄ±n aynÄ± olduÄŸunu modelimizin bu ÅŸekilde (1) ayÄ±rt etmesini istiyoruz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerekli kÃ¼tÃ¼phaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from transformers import AdamW, AutoConfig, AutoModelForPreTraining, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from random import shuffle\n",
    "from random import random as rand\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import sys\n",
    "import os\n",
    "from random import randrange\n",
    "from datetime import datetime\n",
    "from utils import get_emoji_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.00003\n",
    "wd = 0.1\n",
    "loss_multiplier = 5\n",
    "transformer_name = \"mbert\"\n",
    "\n",
    "# Transformerdaki CLS ve SEP taglerinin tanÄ±mlanmasÄ±\n",
    "cls_tag = 101\n",
    "sep_tag = 102\n",
    "if transformer_name==\"distilberturk\":\n",
    "    cls_tag = 2\n",
    "    sep_tag = 3\n",
    "\n",
    "embedding_layer = True\n",
    "last_free_layer = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transformer_name==\"mbert\":\n",
    "    config = AutoConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "    config.output_hidden_states = True\n",
    "elif transformer_name==\"distilberturk\":\n",
    "    config = AutoConfig.from_pretrained('dbmdz/distilbert-base-turkish-cased')\n",
    "    config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaskelenmiÅŸ Dil Modeli'nin eklendiÄŸi modelin tanÄ±mlanmasÄ± "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cls', 'pooler', 'embedding', 'encoder.layer.0', 'encoder.layer.1', 'encoder.layer.2', 'encoder.layer.3', 'encoder.layer.4', 'encoder.layer.5', 'encoder.layer.6', 'encoder.layer.7', 'encoder.layer.8', 'encoder.layer.9', 'encoder.layer.10', 'encoder.layer.11']\n",
      "[FREE]: bert.embeddings.word_embeddings.weight\n",
      "[FREE]: bert.embeddings.position_embeddings.weight\n",
      "[FREE]: bert.embeddings.token_type_embeddings.weight\n",
      "[FREE]: bert.embeddings.LayerNorm.weight\n",
      "[FREE]: bert.embeddings.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.0.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.0.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.0.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.0.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.0.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.0.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.0.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.0.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.0.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.0.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.0.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.0.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.1.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.1.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.1.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.1.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.1.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.1.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.1.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.1.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.1.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.1.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.1.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.1.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.2.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.2.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.2.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.2.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.2.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.2.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.2.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.2.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.2.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.2.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.2.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.2.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.3.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.3.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.3.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.3.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.3.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.3.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.3.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.3.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.3.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.3.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.3.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.3.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.4.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.4.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.4.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.4.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.4.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.4.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.4.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.4.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.4.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.4.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.4.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.4.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.5.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.5.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.5.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.5.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.5.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.5.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.5.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.5.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.5.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.5.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.5.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.5.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.6.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.6.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.6.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.6.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.6.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.6.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.6.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.6.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.6.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.6.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.6.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.6.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.6.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.6.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.7.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.7.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.7.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.7.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.7.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.7.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.7.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.7.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.7.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.7.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.7.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.7.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.7.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.7.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.8.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.8.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.8.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.8.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.8.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.8.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.8.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.8.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.8.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.8.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.8.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.8.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.8.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.8.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.9.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.9.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.9.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.9.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.9.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.9.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.9.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.9.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.9.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.9.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.9.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.9.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.9.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.9.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.10.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.10.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.10.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.10.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.10.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.10.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.10.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.10.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.10.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.10.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.10.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.10.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.10.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.10.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.11.attention.self.query.weight\n",
      "[FREE]: bert.encoder.layer.11.attention.self.query.bias\n",
      "[FREE]: bert.encoder.layer.11.attention.self.key.weight\n",
      "[FREE]: bert.encoder.layer.11.attention.self.key.bias\n",
      "[FREE]: bert.encoder.layer.11.attention.self.value.weight\n",
      "[FREE]: bert.encoder.layer.11.attention.self.value.bias\n",
      "[FREE]: bert.encoder.layer.11.attention.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.11.attention.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "[FREE]: bert.encoder.layer.11.intermediate.dense.weight\n",
      "[FREE]: bert.encoder.layer.11.intermediate.dense.bias\n",
      "[FREE]: bert.encoder.layer.11.output.dense.weight\n",
      "[FREE]: bert.encoder.layer.11.output.dense.bias\n",
      "[FREE]: bert.encoder.layer.11.output.LayerNorm.weight\n",
      "[FREE]: bert.encoder.layer.11.output.LayerNorm.bias\n",
      "[FREE]: bert.pooler.dense.weight\n",
      "[FREE]: bert.pooler.dense.bias\n",
      "[FREE]: cls.predictions.bias\n",
      "[FREE]: cls.predictions.transform.dense.weight\n",
      "[FREE]: cls.predictions.transform.dense.bias\n",
      "[FREE]: cls.predictions.transform.LayerNorm.weight\n",
      "[FREE]: cls.predictions.transform.LayerNorm.bias\n",
      "[FREE]: cls.seq_relationship.weight\n",
      "[FREE]: cls.seq_relationship.bias\n",
      "Combined Net tanÄ±mlandÄ±.\n"
     ]
    }
   ],
   "source": [
    "class Combined_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Combined_Net, self).__init__()\n",
    "        if transformer_name==\"distilberturk\":\n",
    "            self.net_bert = AutoModelForPreTraining.from_config(config).from_pretrained('dbmdz/distilbert-base-turkish-cased', output_hidden_states=True)\n",
    "        elif transformer_name==\"mbert\":\n",
    "            self.net_bert = AutoModelForPreTraining.from_config(config).from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)\n",
    "        unfrozen_layers = [\"cls\", \"pooler\"]\n",
    "        if embedding_layer:\n",
    "            unfrozen_layers.append('embedding')\n",
    "        \n",
    "        for idx in range(last_free_layer, 12):\n",
    "            if transformer_name==\"distilberturk\":\n",
    "                unfrozen_layers.append('transformer.layer.'+str(idx))\n",
    "            elif transformer_name==\"mbert\":\n",
    "                unfrozen_layers.append('encoder.layer.'+str(idx))\n",
    "            \n",
    "            \n",
    "        print(unfrozen_layers)\n",
    "        for name, param in self.net_bert.named_parameters():\n",
    "            if not any([layer in name for layer in unfrozen_layers]):\n",
    "                print(\"[FROZE]: %s\" % name)\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                print(\"[FREE]: %s\" % name)\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input_ids, input_attention, input_types, input_ids_masked, input_attention_masked, input_types_masked):\n",
    "        if transformer_name==\"mbert\":\n",
    "            _, _, x  = self.net_bert(input_ids, attention_mask=input_attention, token_type_ids=input_types)\n",
    "            probs, _, _  = self.net_bert(input_ids_masked, attention_mask=input_attention_masked, token_type_ids=input_types_masked)\n",
    "        elif transformer_name==\"distilberturk\":\n",
    "            _, x  = self.net_bert(input_ids, attention_mask=input_attention)\n",
    "            probs, _  = self.net_bert(input_ids_masked, attention_mask=input_attention_masked)\n",
    "    \n",
    "\n",
    "        #Getting head\n",
    "        x = x[-1][:,0,:]\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        return x, probs\n",
    "\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "try:\n",
    "    combined_net.apply(weight_reset)\n",
    "    print('Combined Net resetlendi.')\n",
    "except: \n",
    "    pass\n",
    "\n",
    "combined_net = Combined_Net().to(device)\n",
    "print('Combined Net tanÄ±mlandÄ±.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if transformer_name==\"distilberturk\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained('dbmdz/distilbert-base-turkish-cased')\n",
    "elif transformer_name==\"mbert\":\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mandalina Emoji Verileri Ã¼zerinden otomatik olarak ikililerin oluÅŸturulmasÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_emoji_pairs(\"../Veriler/emoji.csv\")\n",
    "tokenizer_vocabs = list(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaskelenmiÅŸ Dil Modeli iÃ§in otomatik bir ÅŸekilde eÄŸitim verisinin oluÅŸturulmasÄ± ve Ã¶znitelik Ã§Ä±karma kodlarÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_masked(original_sent):\n",
    "\n",
    "    max_pred = 20\n",
    "    mask_prob = 0.15\n",
    "    max_len = 256\n",
    "    first_part = list(tokenizer.encode(original_sent[0], add_special_tokens=False))\n",
    "    second_part = list(tokenizer.encode(original_sent[1], add_special_tokens=False))\n",
    "    feature = [cls_tag]+first_part+[sep_tag]+second_part+[sep_tag]\n",
    "    if len(feature)>256:\n",
    "        print('Error in ',original_sent)\n",
    "        feature = feature[:255]+[sep_tag]\n",
    "    mid_index = len(first_part)+2\n",
    "    input_type = [0]*mid_index+(len(feature)-mid_index)*[1]\n",
    "    \n",
    "    masked_tokens = []\n",
    "    masked_pos = []\n",
    "    tokens = tokenizer.convert_ids_to_tokens(feature)\n",
    "    input_mask = [1]*len(tokens)\n",
    "    n_pred = min(max_pred, max(1, int(round(len(tokens)*mask_prob))))\n",
    "    cand_pos = [i for i, token in enumerate(tokens)\n",
    "                if token != '[CLS]' and token != '[SEP]' and token != '[unused5]']\n",
    "    shuffle(cand_pos)\n",
    "\n",
    "    for pos in cand_pos[:n_pred]:\n",
    "        masked_tokens.append(tokens[pos])\n",
    "        masked_pos.append(pos)\n",
    "        if rand() < 0.8: # 80%\n",
    "            tokens[pos] = '[MASK]'\n",
    "        elif rand() < 0.5: # 10%\n",
    "            tokens[pos] = tokenizer_vocabs[random.randrange(len(tokenizer_vocabs))]\n",
    "\n",
    "            \n",
    "#     masked_weights = [1]*len(masked_tokens)\n",
    "    \n",
    "    masked_lm_labels = [-100]*max_len\n",
    "    for pos in masked_pos:\n",
    "        masked_lm_labels[pos] = feature[pos]\n",
    "    # Token Indexing\n",
    "    input_ids = tokenizer.encode(tokens, add_special_tokens=False)\n",
    "#     masked_ids = tokenizer.encode(masked_tokens, add_special_tokens=False)\n",
    "    n_pad = max_len - len(input_ids)\n",
    "    input_ids.extend([0]*n_pad)\n",
    "    input_mask.extend([0]*n_pad)\n",
    "    input_type.extend([0]*n_pad)\n",
    "    \n",
    "        # Zero Padding for masked target\n",
    "#     if max_pred > n_pred:\n",
    "#         n_pad = max_pred - n_pred\n",
    "#         masked_ids.extend([0]*n_pad)\n",
    "#         masked_pos.extend([0]*n_pad)\n",
    "#         masked_weights.extend([0]*n_pad)\n",
    "\n",
    "    return torch.tensor(input_ids), torch.tensor(input_mask), torch.tensor(input_type), torch.tensor(masked_lm_labels)\n",
    "\n",
    "def to_masked_all(X):\n",
    "    ids = []\n",
    "    mask = []\n",
    "    types = []\n",
    "    labels = []\n",
    "    for _, original_sent in X:\n",
    "        try:\n",
    "            input_ids, input_mask, input_type, masked_lm_labels = to_masked(original_sent)\n",
    "        except:\n",
    "            print(original_sent)\n",
    "            raise Exception\n",
    "        ids.append(input_ids)\n",
    "        mask.append(input_mask)\n",
    "        types.append(input_type)\n",
    "        labels.append(masked_lm_labels)\n",
    "    return torch.stack(ids),torch.stack(mask),torch.stack(types),torch.stack(labels)\n",
    "\n",
    "def to_id(first_text, second_text):\n",
    "    ids_1 = tokenizer.encode(first_text, add_special_tokens=False)\n",
    "    ids_2 = tokenizer.encode(second_text, add_special_tokens=False)\n",
    "    return torch.tensor([cls_tag]+ids_1+[sep_tag]+ids_2+[sep_tag])\n",
    "\n",
    "def feat_ext(data):\n",
    "    features = []\n",
    "    attention_masks = []\n",
    "    type_ids = []\n",
    "    max_len = 256\n",
    "    for input_ids, _ in data:\n",
    "        first_ind = list(input_ids).index(sep_tag)+1\n",
    "        if transformer_name==\"distilberturk\":\n",
    "            type_id = []\n",
    "        elif transformer_name==\"mbert\":\n",
    "            type_id = torch.cat((torch.tensor([0]*(first_ind)), torch.tensor([1]*(len(input_ids)-first_ind)),torch.tensor([0]*(max_len-len(input_ids)))), 0)\n",
    "        attention_mask = torch.cat((torch.tensor([1.0]*(len(input_ids))), torch.tensor([0.0]*(max_len-len(input_ids)))), 0)\n",
    "        input_ids = torch.cat((input_ids, torch.tensor([0]*(max_len-len(input_ids)))), 0)        \n",
    "        attention_masks.append(attention_mask)\n",
    "        features.append(input_ids)\n",
    "        type_ids.append(torch.tensor(type_id))\n",
    "    return torch.stack(features),torch.stack(attention_masks),torch.stack(type_ids)\n",
    "\n",
    "def feat_ext_batch(subset_df):\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    for idx, row in subset_df.iterrows():\n",
    "        id_seq = to_id(row['text1'], row['text2'])\n",
    "        if len(id_seq)>=256:\n",
    "            ct+=1\n",
    "            continue\n",
    "        X.append((id_seq, (row['text1'], row['text2'])))\n",
    "        y.append([row['class']*1.0])\n",
    "    X_feat, X_attention, X_types = feat_ext(X)\n",
    "    X_feat_masked, X_attention_masked, X_types_masked, X_masked_lm_labels = to_masked_all(X)\n",
    "    y = torch.tensor(y)\n",
    "    return X_feat, X_attention, X_types, X_feat_masked, X_attention_masked, X_types_masked, X_masked_lm_labels, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoji veri setinin eÄŸitim ve test kÄ±sÄ±mlarÄ±nÄ±n ayrÄ±lmasÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.95\n",
    "train_df = df[msk]\n",
    "test_df = df[~msk].reset_index(drop=True)\n",
    "msk = np.random.rand(len(train_df)) < 0.94\n",
    "val_df = train_df[~msk].reset_index(drop=True)\n",
    "train_df = train_df[msk].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer ve loss fonksiyonun belirlenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lm_criterion = CrossEntropyLoss()\n",
    "\n",
    "optimizer = AdamW(combined_net.parameters(), lr=learning_rate,  correct_bias=False, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dil modeli ve emoji ikili sÄ±nÄ±flandÄ±rma iÃ§in tahminleri dÃ¶nen kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(df):\n",
    "    batch_size = 16\n",
    "    lm_loss = 0\n",
    "    cl_loss = 0\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.tensor([], device='cpu')\n",
    "        y_test = torch.tensor([], device='cpu')\n",
    "        for idx in tqdm(range(math.ceil(len(df)/batch_size)), total=math.ceil(len(df)/batch_size)):\n",
    "            inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m, input_masked_labels, y_test_sub = feat_ext_batch(df[idx*batch_size: min(len(df), (idx+1)*batch_size)])\n",
    "\n",
    "            inputs_0 = inputs_0.to(device)\n",
    "            input_attention = input_attention.to(device)\n",
    "            input_type = input_type.to(device)\n",
    "            inputs_0_m = inputs_0_m.to(device)\n",
    "            input_attention_m = input_attention_m.to(device)\n",
    "            input_type_m = input_type_m.to(device)\n",
    "\n",
    "            o, probs = combined_net(inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m) \n",
    "            outputs = torch.cat((outputs, o.to('cpu')), 0)\n",
    "            y_test = torch.cat((y_test, y_test_sub), 0)\n",
    "            \n",
    "            lm_loss += lm_criterion(probs.to('cpu').view(-1, config.vocab_size), input_masked_labels.view(-1))\n",
    "            cl_loss += criterion(o.to('cpu'), y_test_sub)\n",
    "        predicted_test = torch.sigmoid(outputs)>0.5\n",
    "        total = y_test.size(0)\n",
    "        correct = (predicted_test == y_test).sum().item()\n",
    "        test_acc = correct/total\n",
    "\n",
    "    test_f1 = f1_score(predicted_test.cpu(), y_test.cpu())\n",
    "    return test_f1, test_acc, lm_loss, cl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akoksal/.local/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1_1-0,    64/223284] loss: 7.220 lm_loss: 3.756 cl_loss: 0.693  |  accuracy: 0.512\n",
      "[1_2-0,   128/223284] loss: 8.132 lm_loss: 4.644 cl_loss: 0.698  |  accuracy: 0.502\n",
      "[1_3-0,   192/223284] loss: 7.536 lm_loss: 4.071 cl_loss: 0.693  |  accuracy: 0.488\n",
      "[1_4-0,   256/223284] loss: 7.388 lm_loss: 3.897 cl_loss: 0.698  |  accuracy: 0.484\n",
      "[1_5-0,   320/223284] loss: 7.289 lm_loss: 3.856 cl_loss: 0.686  |  accuracy: 0.502\n",
      "[1_6-0,   384/223284] loss: 7.525 lm_loss: 3.842 cl_loss: 0.737  |  accuracy: 0.494\n",
      "[1_7-0,   448/223284] loss: 7.173 lm_loss: 3.702 cl_loss: 0.694  |  accuracy: 0.495\n",
      "[1_8-0,   512/223284] loss: 7.328 lm_loss: 3.843 cl_loss: 0.697  |  accuracy: 0.495\n",
      "[1_9-0,   576/223284] loss: 7.149 lm_loss: 3.690 cl_loss: 0.692  |  accuracy: 0.498\n",
      "[1_10-0,   640/223284] loss: 7.112 lm_loss: 3.650 cl_loss: 0.692  |  accuracy: 0.501\n",
      "[1_11-0,   704/223284] loss: 7.153 lm_loss: 3.676 cl_loss: 0.695  |  accuracy: 0.500\n",
      "[1_12-0,   768/223284] loss: 7.054 lm_loss: 3.589 cl_loss: 0.693  |  accuracy: 0.501\n",
      "[1_13-0,   832/223284] loss: 7.015 lm_loss: 3.543 cl_loss: 0.694  |  accuracy: 0.498\n",
      "[1_14-0,   896/223284] loss: 7.073 lm_loss: 3.611 cl_loss: 0.692  |  accuracy: 0.498\n",
      "[1_15-0,   960/223284] loss: 7.170 lm_loss: 3.703 cl_loss: 0.693  |  accuracy: 0.499\n",
      "[1_16-0,  1024/223284] loss: 6.895 lm_loss: 3.417 cl_loss: 0.696  |  accuracy: 0.499\n",
      "[1_17-0,  1088/223284] loss: 6.863 lm_loss: 3.393 cl_loss: 0.694  |  accuracy: 0.499\n",
      "[1_18-0,  1152/223284] loss: 6.896 lm_loss: 3.413 cl_loss: 0.696  |  accuracy: 0.499\n",
      "[1_19-0,  1216/223284] loss: 7.024 lm_loss: 3.551 cl_loss: 0.695  |  accuracy: 0.498\n",
      "[1_20-0,  1280/223284] loss: 6.891 lm_loss: 3.406 cl_loss: 0.697  |  accuracy: 0.496\n",
      "[1_21-0,  1344/223284] loss: 6.927 lm_loss: 3.460 cl_loss: 0.693  |  accuracy: 0.497\n",
      "[1_22-0,  1408/223284] loss: 6.893 lm_loss: 3.429 cl_loss: 0.693  |  accuracy: 0.497\n",
      "[1_23-0,  1472/223284] loss: 6.904 lm_loss: 3.436 cl_loss: 0.694  |  accuracy: 0.497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-84f53a4cbb18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtotal\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtrain_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "batch_size = 4\n",
    "best_val_loss = np.inf\n",
    "accumulation_steps = 64\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_cl_loss = 0.0\n",
    "    running_lm_loss = 0.0\n",
    "    total_loss = 0\n",
    "    total_cl_loss = 0.0\n",
    "    total_lm_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "    val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "    train_outputs = torch.BoolTensor([]).to(device)\n",
    "    for idx in range(math.ceil(len(train_df)/batch_size)):\n",
    "        inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m, input_masked_labels, labels = feat_ext_batch(train_df[idx*batch_size: min(len(train_df), (idx+1)*batch_size)])\n",
    "        inputs_0 = inputs_0.to(device)\n",
    "        input_attention = input_attention.to(device)\n",
    "        input_type = input_type.to(device)\n",
    "        inputs_0_m = inputs_0_m.to(device)\n",
    "        input_attention_m = input_attention_m.to(device)\n",
    "        input_type_m = input_type_m.to(device)\n",
    "        input_masked_labels = input_masked_labels.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs, probs = combined_net(inputs_0, input_attention, input_type, inputs_0_m, input_attention_m, input_type_m)\n",
    "        \n",
    "        lm_loss = lm_criterion(probs.view(-1, config.vocab_size), input_masked_labels.view(-1)) / accumulation_steps \n",
    "\n",
    "        predicted = torch.sigmoid(outputs)>0.5\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total+= len(labels)\n",
    "        train_outputs = torch.cat((train_outputs, predicted), 0)\n",
    "        # forward + backward + optimize\n",
    "        cl_loss = criterion(outputs, labels) / accumulation_steps \n",
    "        \n",
    "        loss = loss_multiplier*cl_loss + lm_loss\n",
    "        loss.backward()\n",
    "        \n",
    "        if (idx+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
    "            optimizer.step()                            # Now we can do an optimizer step\n",
    "            optimizer.zero_grad()                           # Reset gradients tensors\n",
    "#             scheduler.step()\n",
    "        \n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_cl_loss += cl_loss.item()\n",
    "        running_lm_loss += lm_loss.item()\n",
    "        if (idx+1) % accumulation_steps == 0:    # print every 2000 mini-batches\n",
    "            print('[%d_%d-%d, %5d/%d] loss: %.3f lm_loss: %.3f cl_loss: %.3f  |  accuracy: %.3f' %\n",
    "                  (epoch + 1, (idx + 1)//accumulation_steps,(idx + 1)%accumulation_steps, idx + 1, len(train_df)//batch_size, running_loss, running_lm_loss, running_cl_loss, correct/total))\n",
    "            total_loss += running_loss\n",
    "            total_cl_loss += running_cl_loss\n",
    "            total_lm_loss += running_lm_loss\n",
    "            running_loss = 0.0\n",
    "            running_cl_loss = 0 \n",
    "            running_lm_loss = 0\n",
    "        \n",
    "\n",
    "            \n",
    "    train_acc = correct/total\n",
    "    print(train_acc)\n",
    "    \n",
    "    test_f1, test_acc, test_lm_loss, test_cl_loss = get_predictions(test_df)\n",
    "    test_loss = (loss_multiplier*test_cl_loss) + test_lm_loss\n",
    "    val_f1, val_acc, val_lm_loss, val_cl_loss = get_predictions(val_df)\n",
    "    val_loss = (loss_multiplier*val_cl_loss) + val_lm_loss\n",
    "   \n",
    "    if val_loss<best_val_loss:\n",
    "        now = datetime.now()\n",
    "        torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': combined_net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': total_loss\n",
    "                }, f'../Models/{transformer_name}_pair_f1_{test_f1}_acc_{test_acc}_{epoch+1}.pt')\n",
    "    print('Epoch: ',epoch+1)\n",
    "    print(f'Loss: {total_loss}, LM Loss: {total_lm_loss}, CL Loss: {total_cl_loss}, Training accuracy:{train_acc}, Validation accuracy:{val_acc}, Test accuracy:{test_acc}')\n",
    "    print(f'Val F1:{val_f1} \\t Val Loss: {val_loss} Val CL Loss: {val_cl_loss} Val LM Loss: {val_lm_loss}')\n",
    "    print(f'Test F1:{test_f1} \\t Test Loss: {test_loss} Test CL Loss: {test_cl_loss}  LM Loss: {val_lm_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
